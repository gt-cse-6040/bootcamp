{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxT-4Efmoeh0"
   },
   "source": [
    "# Pandas Functions: Index, Concat, Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-BmzcuYSdRq"
   },
   "source": [
    "***\n",
    "## The content of this notebook is a continuation of the Pandas classroom lectures conducted by Professor Vuduc. These lectures are posted as videos on Canvas, under Topic 7.\n",
    "\n",
    "## This notebook presupposes that students have already watched those videos, and that they have some understanding of the content.\n",
    "\n",
    "## We will not be covering, or answering questions about, that foundational content here.\n",
    "\n",
    "## Please post any questions about that content to Piazza.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snP6N-Lloeh2"
   },
   "source": [
    "**The below three cells simply set up the NB with the same two df's as in Professor Vuduc's classroom lectures.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Cfc-dSSoeh3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd  # Standard idiom for loading pandas\n",
    "from pandas import DataFrame, Series\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VTu7dFd-oeh3"
   },
   "outputs": [],
   "source": [
    "cafes = DataFrame({'name': ['east pole', 'chrome yellow', 'brash', 'taproom', '3heart', 'spiller park pcm', 'refuge', 'toptime'],\n",
    "                   'zip': [30324, 30312, 30318, 30317, 30306, 30308, 30303, 30318],\n",
    "                   'poc': ['jared', 'kelly', 'matt', 'jonathan', 'nhan', 'dale', 'kitti', 'nolan']})\n",
    "\n",
    "cafes2 = cafes[['poc', 'zip']]\n",
    "cafes2.index = cafes['name']\n",
    "cafes2.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UenA9TDRoeh4"
   },
   "outputs": [],
   "source": [
    "cafes2['rating'] = 4.0\n",
    "cafes2['price'] = '$$'\n",
    "prices_as_ints = cafes2['price'].apply(lambda s: len(s))\n",
    "cafes2['value'] = cafes2['rating'] / prices_as_ints\n",
    "cafes3 = cafes2.copy()\n",
    "is_fancy = cafes3['zip'].isin({30306, 30308})\n",
    "cafes3.loc[is_fancy, 'price'] += '$'\n",
    "cafes4 = cafes3.copy()\n",
    "def calc_value(row):\n",
    "    return row['rating'] / len(row['price'])\n",
    "\n",
    "cafes4['value'] = cafes4.apply(calc_value, axis=1)\n",
    "cafes4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eiD44P9moeh4"
   },
   "source": [
    "## Index objects\n",
    "\n",
    "A pandas [`Index`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Index.html), used by `Series` and `DataFrame`, is \"list-like.\" It has a number of useful operations, including set-like operations (e.g., testing for membership, intersection, union, difference).\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/indexing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OlNS_n0moeh4"
   },
   "outputs": [],
   "source": [
    "from pandas import Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2QD7b925oeh5"
   },
   "outputs": [],
   "source": [
    "# what are the index names?\n",
    "cafes4.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NjZoYl3gSdRz"
   },
   "source": [
    "#### Index values can be duplicated, so there can be more than one row with the same index value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5SnF1Mu1SdRz"
   },
   "outputs": [],
   "source": [
    "idx = pd.Index(['Labrador', 'Beagle', 'Labrador',\n",
    "                      'Lhasa', 'Husky', 'Beagle'])\n",
    "\n",
    "# Print the Index\n",
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q90xj-LCSdR0"
   },
   "source": [
    "We can use the `Index.duplicated()` function to identify all the duplicate values.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Index.duplicated.html\n",
    "\n",
    "In the example below, all the duplicate values will be marked as `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9QPiCY1sSdR0"
   },
   "outputs": [],
   "source": [
    "# Identify all duplicated occurrence of values\n",
    "idx.duplicated(keep = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zo5S5nXPSdR1"
   },
   "source": [
    "The `isin()` function returns a boolean mask array, in which each row of the mask array has a `True/False` value, if that row meets or does not meet the `isin()` criteria.\n",
    "\n",
    "We will cover boolean masks in some detail in tomorrow's session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ES03MUQoeh5"
   },
   "outputs": [],
   "source": [
    "# boolean mask/membership\n",
    "cafes4.index.isin(['brash', '3heart'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8QDE0ngoeh5"
   },
   "source": [
    "#### The next few cells show index operations, to illustrate some things that you can do with indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tsLqRClmoeh5"
   },
   "outputs": [],
   "source": [
    "# create an union with a new value\n",
    "cafes4.index.union(['chattahoochee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kjNg2lMNoeh5"
   },
   "outputs": [],
   "source": [
    "# return the difference\n",
    "cafes4.index.difference(['chattahoochee', 'starbucks', 'bar crema'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSEt1JT-oeh6"
   },
   "source": [
    "If you need to change the index of a `DataFrame`, here is one way to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "98Hpk_2toeh6"
   },
   "outputs": [],
   "source": [
    "cafes5 = cafes4.reindex(Index(['3heart', 'east pole', 'brash', 'starbucks']))\n",
    "\n",
    "display(cafes4)\n",
    "display(cafes5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGk7OWGboeh6"
   },
   "source": [
    "Observe that this reindexing operation matches the supplied index values against the existing ones. (What happens to index values you leave out? What happens with new index values?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FiI0w30qoeh6"
   },
   "source": [
    "### Tap, tap, tap\n",
    "\n",
    "**Below is an index operation that is useful. You will see this in future NB's and can expect to be asked to apply this funcationality in testing scenarios (MT2 and Final exam).**\n",
    "\n",
    "**As an aside, you can expect to be required to show your proficiency with everything in this NB on the exams.**\n",
    "\n",
    "Another useful operation is dropping the index (and replacing it with the default, integers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNBo4Ndnoeh6"
   },
   "outputs": [],
   "source": [
    "# display for initial reference\n",
    "cafes4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3G9NWVd2oeh6"
   },
   "outputs": [],
   "source": [
    "# create a new df, cafes6, and\n",
    "# reset the index from the string names to integers\n",
    "cafes6 = cafes4.reset_index(drop=True)\n",
    "cafes6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_q16VlToeh6"
   },
   "source": [
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reset_index.html\n",
    "\n",
    "From the documentation:  Reset the index of the DataFrame, and use the default one instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0RiQ3z14oeh6"
   },
   "outputs": [],
   "source": [
    "# create a new column from the index of the other df\n",
    "# recall that the other index is strings\n",
    "cafes6['name'] = cafes4.index\n",
    "cafes6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHiouidaoeh6"
   },
   "source": [
    "### Now let's look at the concat() function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7McXwVKoeh7"
   },
   "source": [
    "Another useful operation is gluing `DataFrame` objects together. There are several helpful operations covered in Notebook 7; one not mentioned there, but useful in one of its exercises, is `.concat()`.\n",
    "\n",
    "The below material is partially adapted from \"The Python Data Science Handbook\" by Jake VanderPlas, Chapter 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rI_vxjA4oeh7"
   },
   "source": [
    "Here is the documentation page for .concat():\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html\n",
    "\n",
    "Note that the only arguments required are the objects to be concatenated.\n",
    "\n",
    "1. The default axis=0, which means the concatenation is done along the indexes (rows). From a practical perspective, what this means is that the second listed df (or 3rd, 4th, etc) is \"attached\" to the bottom of the 1st listed dataframe.\n",
    "\n",
    "2. The default join is 'outer' join, which means to bring all rows in. We will cover joins in detail during our SQL module, but in this case, the outer join means to bring in all rows from both dataframes.\n",
    "\n",
    "3. Pandas concatenation preserves indexes, even if the result will have duplicate indexes. The verify_integrity option handles duplicates, and please see the documentation for specifics. You will generally not need to worry about this option during the class.\n",
    "\n",
    "So let's look at an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-4i2PBjmoeh7"
   },
   "outputs": [],
   "source": [
    "# Split based on price\n",
    "# create a boolean mask\n",
    "is_cheap = cafes4['price'] <= '$$'\n",
    "\n",
    "# create 2 df's, based on the mask\n",
    "cafes_cheap = cafes4[is_cheap]   #cheap\n",
    "cafes_pricey = cafes4[~is_cheap]  #not cheap\n",
    "\n",
    "display(cafes_cheap)\n",
    "display(cafes_pricey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GJTSm0tZoeh7"
   },
   "outputs": [],
   "source": [
    "# Never mind; recombine\n",
    "pd.concat([cafes_cheap, cafes_pricey])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSLHKug8oeh7"
   },
   "source": [
    "The .concate() function will bring together dataframes with the same column names and will also join those with different column names. In general, we will not exercise the latter case in this class, but there are numerous examples available online which show how pandas does this. A very good reference with examples is VanderPlas:\n",
    "\n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/03.06-concat-and-append.html\n",
    "\n",
    "https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.06-Concat-And-Append.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yv5YyQBXoeh7"
   },
   "source": [
    "### Next is the merge() function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dM62Kfboeh7"
   },
   "source": [
    "One essential feature offered by Pandas is its high-performance, in-memory join and merge operations.\n",
    "If you have ever worked with databases, you should be familiar with this type of data interaction.\n",
    "\n",
    "In SQL, this is a select and join of two tables.\n",
    "\n",
    "The main interface for this is the ``pd.merge`` function, which you will use extensively in this class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4t8Dz5mBoeh7"
   },
   "source": [
    "Here is the documentation page for .merge():\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge.html\n",
    "\n",
    "The first 6 parameters are important for us to know about, and to know how to use. You may use the remaining parameters, but these first 6 are absolutely necessary for you to understand and use.\n",
    "\n",
    "**pandas.merge(left, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None)**\n",
    "\n",
    "\n",
    "1. The 'left' and 'right' parameters define the two dataframes to merge on. It is important for you to designate and remember which df is left and which is right, as 3 of the 4 remaining parameters use them.\n",
    "\n",
    "2. The 'how' parameter designates the type of join operation to perform (left, right, outer, inner, cross). We will cover these in detail during our SQL module next week.\n",
    "\n",
    "3. The 'on' parameter gives the column(s) or index level names to join on. Whatever you designate for this parameter must be contained in both the left and right df's.\n",
    "\n",
    "4. You can use the 'left_on' and 'right_on' parameters when the two dataframes do not have identically-named columns, but they have differently-named columns that have the same values, and you can join on them. We will show an example of this below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wD3dwEGgoeh7"
   },
   "source": [
    "**Specifying the merge key:**\n",
    "\n",
    "The default behavior of pd.merge() is that it looks for one or more matching column names between the two inputs, and uses this as the key. Note that the default value for the 'on' parameter is None, so if you do not specify the column names to merge on, the function will attempt to execute its default behavior.\n",
    "\n",
    "However, often the column names will not match so nicely, and pd.merge() provides a variety of options for handling this.\n",
    "\n",
    "You have several options for specifying how to merge:\n",
    "\n",
    "1. You can explicitly specify the name of the key column using the on keyword, which takes a column name or a list of column names. Note that this only works if both the left and right dataframes have the specified column name.\n",
    "\n",
    "2. The left_on and right_on keywords are useful when you want to merge two datasets with different column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yUhV1wC5oeh7"
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue','Chris','Rich'],\n",
    "                    'group': ['Accounting', 'Engineering', 'Engineering', 'HR','IT','Engineering']})\n",
    "df2 = pd.DataFrame({'employee': ['Lisa', 'Bob', 'Jake', 'Sue'],\n",
    "                    'hire_date': [2004, 2008, 2012, 2014]})\n",
    "df3 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    'salary': [70000, 80000, 120000, 90000]})\n",
    "display(df1, df2,df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6HFKPD2Roeh7"
   },
   "outputs": [],
   "source": [
    "# option 1 above, using on\n",
    "display(df1, df2, pd.merge(df1, df2, on='employee'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quyaLKH_oeh7"
   },
   "outputs": [],
   "source": [
    "# option 2 above, using left_on and right_on\n",
    "# note the designation of the left and right df's, and then using the correct *_on column names\n",
    "display(df1, df3, pd.merge(df1, df3, left_on=\"employee\", right_on=\"name\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evzfsuytoeh8"
   },
   "source": [
    "**The default value for the 'how' parameter is inner. As the documentation states:  inner: use intersection of keys from both frames, similar to a SQL inner join; preserve the order of the left keys.**\n",
    "\n",
    "In layman's terms, what this means is that the only keys returned will be those that are in both the left and right df's.\n",
    "\n",
    "Review againg the first join between df1 and df2. The key values from df2 of 'Rich' and 'Chris' are not in df1, so they are not included in the inner join.\n",
    "\n",
    "So let's set the join to outer and see what happens.**Again, from the documentation:  outer: use union of keys from both frames, similar to a SQL full outer join; sort keys lexicographically.**\n",
    "\n",
    "Additionally, the outer join fills in all missing values with NAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VFx79RqZoeh8"
   },
   "outputs": [],
   "source": [
    "# option 1 above, using on, this time as an outer join\n",
    "display(df1, df2, pd.merge(df1, df2, on='employee', how='outer'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kv34xyFjoeh8"
   },
   "source": [
    "See the 'hire_date' values for Chris and Rich, they are NaN values, as specified.\n",
    "\n",
    "We will spend more time on the join types in SQL next week, and know that all of the behaviors you will learn about then will apply here. We simply want to introduce you to the function here.\n",
    "\n",
    "As noted above, the VanderPlas book has excellent coverage of this topic:\n",
    "\n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/03.07-merge-and-join.html\n",
    "\n",
    "https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.07-Merge-and-Join.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uCNaKohoeh9"
   },
   "source": [
    "**This concludes our introduction to some important pandas functions.**\n",
    "\n",
    "**We encourage you to delve deeper into them, as you will be using all of these throughout this class and professionally in working with Python for Analytics.**\n",
    "\n",
    "**We also highly encourage you to work through NB7 Part1, the FEC Dataset notebook, as is does a full analysis of 'real life' data from the Federal Election Commission, including application of the above functions that we have covered here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iMrMVANfoeh9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "nteract": {
   "version": "0.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
