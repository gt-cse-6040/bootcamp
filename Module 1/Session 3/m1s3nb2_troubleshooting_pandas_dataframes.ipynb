{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gt-cse-6040/bootcamp/blob/main/Module%201/Session%203/m1s3nb2_troubleshooting_pandas_dataframes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2df20b4c",
      "metadata": {
        "id": "2df20b4c"
      },
      "source": [
        "# Troubleshooting pandas dataframes for the exams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-a3tYQGH31bN",
      "metadata": {
        "id": "-a3tYQGH31bN"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%203/who3.csv\n",
        "!wget https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%203/who3_soln.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6153c6a5",
      "metadata": {
        "id": "6153c6a5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bc79cef",
      "metadata": {
        "id": "2bc79cef"
      },
      "outputs": [],
      "source": [
        "# bring in the two dataframes to work with\n",
        "_input = pd.read_csv('who3.csv')\n",
        "original_input = pd.read_csv('who3_soln.csv')\n",
        "returned_output = pd.read_csv('who3.csv')\n",
        "true_output = pd.read_csv('who3_soln.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca8cd57b",
      "metadata": {
        "id": "ca8cd57b"
      },
      "outputs": [],
      "source": [
        "# put the dataframes into the test case variables\n",
        "input_vars = dict()\n",
        "input_vars['output_0'] = _input\n",
        "original_input_vars = dict()\n",
        "original_input_vars['output_0'] = original_input\n",
        "# not populating this one yet\n",
        "returned_output_vars = dict()\n",
        "# going to be making changes, so this one will be the starting point\n",
        "returned_output_vars_original = dict()\n",
        "returned_output_vars_original['output_0'] = returned_output  #going to be making changes, so this one will be the starting point\n",
        "true_output_vars = dict()\n",
        "true_output_vars['output_0'] = true_output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea5d8b7b",
      "metadata": {
        "id": "ea5d8b7b"
      },
      "source": [
        "## What we want to do is show some techniques for troubleshooting when our dataframe does not match the solution dataframe, when your function returns a pandas dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why are we doing this?\n",
        "\n",
        "### Because many students troubleshoot by simply doing a print() output of their output against the solution/true output, with a visual inspection for differences.\n",
        "\n",
        "### This method does not allow students to \"see\" all of the ways that their solution is tested, and is therefor unreliable and incomplete.\n",
        "\n",
        "### See the screen shots below, from a Piazza post about an exam during the Fall 2023 semester. The first screen shot is the student question, and the second is the TA response."
      ],
      "metadata": {
        "id": "m3UxqDhlxggu"
      },
      "id": "m3UxqDhlxggu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "![P1.png](https://github.com/gt-cse-6040/bootcamp/blob/main/Module%201/Session%203/Piazza_screen_shot_1.png?raw=1)\n",
        "\n",
        "![P2.png](https://github.com/gt-cse-6040/bootcamp/blob/main/Module%201/Session%203/Piazza_screen_shot_2.png?raw=1)"
      ],
      "metadata": {
        "id": "tCeQKP8ZyhyF"
      },
      "id": "tCeQKP8ZyhyF"
    },
    {
      "cell_type": "markdown",
      "id": "d4d5edb1",
      "metadata": {
        "id": "d4d5edb1"
      },
      "source": [
        "## The exam test cells use the pandas function, `assert_frame_equal()` to test for correctness.\n",
        "\n",
        "### This notebook with introduce the function, how it operates, and its usage on the exams.\n",
        "\n",
        "### Then we will look at some troubleshooting techniques that students can use, for both the homework notebooks and the exams."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2379038",
      "metadata": {
        "id": "e2379038"
      },
      "source": [
        "### Steps for today:\n",
        "\n",
        "1. We have the who3 and who3_soln dataframes, from Notebook 7.\n",
        "\n",
        "2. We have put the dataframes into the test case variables, in the manner that they are on the exams.\n",
        "\n",
        "3. Manipulate the `input_vars` and `returned_output_vars` test case variable to show various errors.\n",
        "\n",
        "4. How to troubleshoot and solve for the various errors, when the exercise output requires a pandas dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58bfab90",
      "metadata": {
        "id": "58bfab90"
      },
      "source": [
        "### Let's look (again) at the test case variables.\n",
        "\n",
        "The below text is what is on `EVERY EXERCISE` of `EVERY EXAM`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee1c16cb",
      "metadata": {
        "id": "ee1c16cb"
      },
      "source": [
        "<!-- Test Cell Boilerplate -->\n",
        "The cell below will test your solution for Exercise 1. The testing variables will be available for debugging under the following names in a dictionary format.\n",
        "- `input_vars` - Input variables for your solution.\n",
        "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
        "- `returned_output_vars` - Outputs returned by your solution.\n",
        "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42916434",
      "metadata": {
        "id": "42916434"
      },
      "source": [
        "### So what do the actually look like?\n",
        "\n",
        "### Each test case variable is a dictionary, in the following structure:\n",
        "\n",
        "#### Key: `'output_0'`. The key of the dictionary is always this.\n",
        "\n",
        "#### Value: The value of this key is the actual output from your function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84e1d49e",
      "metadata": {
        "id": "84e1d49e"
      },
      "outputs": [],
      "source": [
        "display(true_output_vars)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a8bc2ef",
      "metadata": {
        "id": "6a8bc2ef"
      },
      "source": [
        "## How does the exam testing operate?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f15d6f06",
      "metadata": {
        "id": "f15d6f06"
      },
      "source": [
        "Let's look at an example of how this works.\n",
        "\n",
        "See the example function definition below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "967d8d8a",
      "metadata": {
        "id": "967d8d8a"
      },
      "outputs": [],
      "source": [
        "def sample_function(_input):\n",
        "\n",
        "    return my_returned_output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "625cf720",
      "metadata": {
        "id": "625cf720"
      },
      "source": [
        "#### What does the testing cell do for the input vars?\n",
        "\n",
        "1. Inserts the value of `_input` into the `original_input_vars` dictionary, for the key `'ouput_0'`.\n",
        "\n",
        "2. Runs your function.\n",
        "\n",
        "3. Inserts the value of `_input` into the `input_vars` dictionary, for the key `'ouput_0'`. Note that this is **after your function has run**, so if you have changed the input parameters in any way, the changed value will show up here.\n",
        "\n",
        "4. Compares the values of the `'output_0'` key, to see if they are the same.\n",
        "\n",
        "5. If the output variable is a pandas dataframe, the testing cell uses the function `assert_frame_equal()` to make the testing comparison.\n",
        "\n",
        "6. Returns a `pass/fail` message. If the test failed, then the returned message is the one that `assert_frame_equal()` provides."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79b40a0f",
      "metadata": {
        "id": "79b40a0f"
      },
      "source": [
        "#### What does the testing cell do for the output vars?\n",
        "\n",
        "1. Runs your function.\n",
        "\n",
        "2. Inserts the value of `my_returned_output` into the `returned_output_vars` dictionary, for the key `'ouput_0'`.\n",
        "\n",
        "3. Compares the values of the `'output_0'` key of the `true_output_vars` and `returned_output_vars` dictionaries, to see if they are the same.\n",
        "\n",
        "4. If the output variable is a pandas dataframe, the testing cell uses the function `assert_frame_equal()` to make the testing comparison.\n",
        "\n",
        "5. Returns a `pass/fail` message. If the test failed, then the returned message is the one that `assert_frame_equal()` provides."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddf5a61c",
      "metadata": {
        "id": "ddf5a61c"
      },
      "source": [
        "### Let's look at the input variables first.\n",
        "\n",
        "#### If the test on your function returns an error on the input variables check, you most likely have made one of the following errors:\n",
        "\n",
        "1. Worked directly on the input variable, instead of making a copy.\n",
        "\n",
        "2. Made a copy of the variable, when you needed to make a deep copy, because the variable contains nested data.\n",
        "\n",
        "3. Added or removed elements from the input variable in your code, as you are executing the function requirements.\n",
        "\n",
        "#### Documentation for copy and deep copy:  https://docs.python.org/3/library/copy.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fcfa8fb",
      "metadata": {
        "id": "5fcfa8fb"
      },
      "outputs": [],
      "source": [
        "#deep copy versus copy syntax\n",
        "from copy import copy\n",
        "from copy import deepcopy\n",
        "\n",
        "input_vars_copy = copy(input_vars)\n",
        "\n",
        "input_vars_deepcopy = deepcopy(input_vars)\n",
        "\n",
        "display(input_vars_copy)\n",
        "display(input_vars_deepcopy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcbfa802",
      "metadata": {
        "id": "dcbfa802"
      },
      "source": [
        "***\n",
        "\n",
        "#### While we are not going to go into detail here, if your data is nested in any way, only `deepcopy` will make a full copy of the data.\n",
        "\n",
        "### Bottom line, you will never be wrong if you use `deepcopy()` whenever you need to make a copy of your input data.\n",
        "\n",
        "### And finally, this is personal preference, but you can never go wrong by making a copy (copies) of the input variables as the first few lines in your function, and doing all of your work with those copies.\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3aa078a",
      "metadata": {
        "id": "e3aa078a"
      },
      "source": [
        "### The second test checks the output of your function (a pandas dataframe in this case) against the pandas dataframe that is the solution.\n",
        "\n",
        "### The test uses the assert_frame_equal() function to do this, after some dataframe manipulation.\n",
        "\n",
        "#### Here is the function documentation:  https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.testing.assert_frame_equal.html\n",
        "\n",
        "#### Let's take a look at the function, in the documentation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9edb4f4d",
      "metadata": {
        "id": "9edb4f4d"
      },
      "source": [
        "### What are the checks that assert_frame_equal() does?\n",
        "\n",
        "1. Checks for data types in the two dfs.\n",
        "2. Checks the number of rows and columns in the two dfs.\n",
        "3. Checks the column names in the two dfs.\n",
        "4. Finally, compares the actual data in the two dfs. This check includes both the data and indexes.  `No direct parameter for this.`\n",
        "\n",
        "#### Let's look at each one individually, and how to troubleshoot."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fda50a97",
      "metadata": {
        "id": "fda50a97"
      },
      "source": [
        "## You can use this Pandas function to do your testing and troubleshooting.\n",
        "\n",
        "## To run your tests, all you need to do is import the function and then call it, passing in the returned_output_variables and true_output variables."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "639f6151",
      "metadata": {
        "id": "639f6151"
      },
      "source": [
        "### We will now set up 4 dataframe examples, that exercise the 4 types of tests that assert_frame_equal() does. The changed dataframes will all be named for the type of change/test we are exercising.\n",
        "\n",
        "#### What we will do is change each df and run some code that shows you how to do individual checks for this test.\n",
        "\n",
        "#### Then we will show how you can do this using the assert_all_equal() function, and let it tell you what has failed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "958dbd81",
      "metadata": {
        "id": "958dbd81"
      },
      "outputs": [],
      "source": [
        "# import the function, students will need to do this on the exams\n",
        "from pandas.testing import assert_frame_equal"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a69d12c",
      "metadata": {
        "id": "8a69d12c"
      },
      "source": [
        "### For our first example, we will change a datatype.\n",
        "\n",
        "https://www.geeksforgeeks.org/get-the-datatypes-of-columns-of-a-pandas-dataframe/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4883bb16",
      "metadata": {
        "id": "4883bb16"
      },
      "outputs": [],
      "source": [
        "# set up the test by changing the datatype\n",
        "returned_output_vars = deepcopy(returned_output_vars_original)\n",
        "returned_output_vars['output_0'][\"count\"] = returned_output_vars['output_0'][\"count\"].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3e449b6",
      "metadata": {
        "id": "b3e449b6"
      },
      "outputs": [],
      "source": [
        "# uncomment to run the test and return the error\n",
        "# a,b = true_output_vars['output_0'], returned_output_vars['output_0']   # data type differences of columns\n",
        "# result = assert_frame_equal(a,b)\n",
        "# result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14f33fae",
      "metadata": {
        "id": "14f33fae"
      },
      "source": [
        "### So we have failed the exercise, and we can see from the AssertionError that our returned output does not match the expected (solution) output.\n",
        "\n",
        "### What do we do now?\n",
        "\n",
        "The **AssertionError** message from the function is very good, and we can see that the datatypes for the column \"count\" are different, and what they are.\n",
        "\n",
        "Note that the \"left\" dataframe is always the first one that you passed in as a parameter, and the \"right\" dataframe is the second parameter.\n",
        "\n",
        "### So we would go back to our code, find the line(s) in which we are assigning the incorrect data type, and change them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e939e571",
      "metadata": {
        "id": "e939e571"
      },
      "outputs": [],
      "source": [
        "# display the column data types\n",
        "display(true_output_vars['output_0'].dtypes)\n",
        "display(returned_output_vars['output_0'].dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01adac99",
      "metadata": {
        "id": "01adac99"
      },
      "source": [
        "### For our second example, we change the number of rows in the dataframe.\n",
        "https://www.geeksforgeeks.org/count-the-number-of-rows-and-columns-of-pandas-dataframe/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc533f0e",
      "metadata": {
        "id": "cc533f0e"
      },
      "outputs": [],
      "source": [
        "# make the copy again, to reset to original\n",
        "returned_output_vars = deepcopy(returned_output_vars_original)\n",
        "# Dropping last 10 rows using drop\n",
        "returned_output_vars['output_0'].drop(returned_output_vars['output_0'].tail(10).index,inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93b8ba7d",
      "metadata": {
        "id": "93b8ba7d"
      },
      "outputs": [],
      "source": [
        "# uncomment to run the test and return the error\n",
        "# # differences in the number of rows of data\n",
        "# a,b = true_output_vars['output_0'], returned_output_vars['output_0']\n",
        "# result = assert_frame_equal(a,b)\n",
        "# result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "796fc4f7",
      "metadata": {
        "id": "796fc4f7"
      },
      "source": [
        "### So we have failed the exercise, and we can see from the AssertionError that our returned output does not match the expected (solution) output.\n",
        "\n",
        "### What do we do now?\n",
        "\n",
        "Again, the **AssertionError** message from the function is very good, and we can see that the dataframes have different shapes, in their number of rows and columns."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b75415bf",
      "metadata": {
        "id": "b75415bf"
      },
      "source": [
        "### When there is length difference your output variables, the most likely reason is that you failed to correctly deal with one of the exercise requirements. You have done one of the following:\n",
        "\n",
        "   **If the number of rows is different:**\n",
        "\n",
        "    1. Included a value that should have been excluded (your output is longer than what it should be).\n",
        "\n",
        "    2. Excluded a value that should have been included (your output is shorter than what it should be).\n",
        "    \n",
        "   **If the number of columns is different:**\n",
        "    \n",
        "    1. Included a column that should have been excluded (your output is wider than what it should be).\n",
        "\n",
        "    2. Excluded a column that should have been included (your output is narrower than what it should be).\n",
        "\n",
        "### At this point, we could output/display the two variables and visually compare them, to see if we can find the missing/extra value.\n",
        "\n",
        "### But the `better method` is to go back to the requirements, your strategy, and your code implementing the strategy, to see if you are handling the edge cases correctly.\n",
        "\n",
        "   **For rows:**\n",
        "\n",
        "    1. If you are using `nlargest()` or `nsmallest()`, are you accounting for the ties correctly?\n",
        "    \n",
        "    2. If you are doing string manipulation, are you accounting for all of the inclusive/exclusive requirements for elements with the string values that you are comparing for?\n",
        "    \n",
        "    3. If you are doing summarizations, have you included all of the required ones (min/max/mean/median), or for time series data, do you have the correct number of periods?\n",
        "    \n",
        "   **For columns:**\n",
        "    \n",
        "    1. Compare the required columns to your columns and add/remove as necessary.\n",
        "\n",
        "### Once we know what the extra/missing value/column is, we must go back to our code and compare it with each of the include/exclude requirements, to see which requirement we did not do correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "878baf7d",
      "metadata": {
        "id": "878baf7d"
      },
      "outputs": [],
      "source": [
        "# # # fetching the number of rows and columns\n",
        "rows_returned = returned_output_vars['output_0'].shape[0]\n",
        "cols_returned = returned_output_vars['output_0'].shape[1]\n",
        "\n",
        "rows_true = true_output_vars['output_0'].shape[0]\n",
        "cols_true = true_output_vars['output_0'].shape[1]\n",
        "\n",
        "# displaying the number of rows and columns\n",
        "print(\"Rows returned: \" + str(rows_returned))\n",
        "print(\"Columns returned: \" + str(cols_returned))\n",
        "print(\"Rows true: \" + str(rows_true))\n",
        "print(\"Columns true: \" + str(cols_true))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35f647bb",
      "metadata": {
        "id": "35f647bb"
      },
      "source": [
        "### For our third example, we will change a couple of column names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64294e26",
      "metadata": {
        "id": "64294e26"
      },
      "outputs": [],
      "source": [
        "# make the copy again, to reset to original\n",
        "returned_output_vars = deepcopy(returned_output_vars_original)\n",
        "\n",
        "# # Change a couple of the column names in the new df, just to generate the error.\n",
        "returned_output_vars['output_0'].rename(columns = {'country':'Country'}, inplace = True)\n",
        "returned_output_vars['output_0'].rename(columns = {'age_group':'age-group'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf70a961",
      "metadata": {
        "id": "cf70a961"
      },
      "outputs": [],
      "source": [
        "# # uncomment to run the test and return the error\n",
        "# # column names different\n",
        "# a,b = true_output_vars['output_0'], returned_output_vars['output_0']\n",
        "# result = assert_frame_equal(a,b)\n",
        "# result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99184cdd",
      "metadata": {
        "id": "99184cdd"
      },
      "source": [
        "### So we have failed the exercise, and we can see from the AssertionError that our returned output does not match the expected (solution) output.\n",
        "\n",
        "### What do we do now?\n",
        "\n",
        "Again, the **AssertionError** message from the function is very good, and we can see that the column names do not match."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d9d5a68",
      "metadata": {
        "id": "3d9d5a68"
      },
      "source": [
        "#### The error message output is very good, in that it lists the column names, one above the other, for a direct visual comparison. Find the difference visually and then go back to the code and change it appropriately.\n",
        "\n",
        "#### However, if we have a very wide data frame, with many columns, the displayed output will not directly line up, so we provide the code below to loop over the column names and direclyt output the differences."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1e93ad2",
      "metadata": {
        "id": "b1e93ad2"
      },
      "source": [
        "#### Here is some template code to check the column names directly, you can use it if you would like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaa6e4ae",
      "metadata": {
        "id": "eaa6e4ae"
      },
      "outputs": [],
      "source": [
        "# check column names directly\n",
        "returned_list = returned_output_vars['output_0'].columns.values.tolist() #change to the true output variables name\n",
        "true_list = true_output_vars['output_0'].columns.values.tolist()    #change to the returned output variables name\n",
        "\n",
        "for i,col_name in enumerate(returned_list):\n",
        "    if col_name != true_list[i]:\n",
        "        print('\\nColumn names do not match')\n",
        "        print('Returned column name: ', col_name)\n",
        "        print('True column name: ', true_list[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f7d4366",
      "metadata": {
        "id": "1f7d4366"
      },
      "source": [
        "#### Finally, let's change some values in the df."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfde0f8f",
      "metadata": {
        "id": "dfde0f8f"
      },
      "outputs": [],
      "source": [
        "# # let's change a few values in our bootcamp dataframe\n",
        "# make the copy again, to reset to original\n",
        "returned_output_vars = deepcopy(returned_output_vars_original)\n",
        "\n",
        "# # make some data changes\n",
        "returned_output_vars['output_0'].at[0, 'count'] = 6\n",
        "returned_output_vars['output_0'].at[1, 'count'] = 2\n",
        "returned_output_vars['output_0'].at[2, 'year'] = 2011\n",
        "returned_output_vars['output_0'].at[3, 'year'] = 2012"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52b54771",
      "metadata": {
        "id": "52b54771"
      },
      "outputs": [],
      "source": [
        "# uncomment to run the test and return the error\n",
        "# data differences\n",
        "# a,b = true_output_vars['output_0'], returned_output_vars['output_0']\n",
        "# result = assert_frame_equal(a,b)\n",
        "# result\n",
        "\n",
        "# Notice that we changed \"count\" and \"year\" above, but the error only returns for \"count\".\n",
        "# The function returns the first column with errors, and you may need to run this multiple\n",
        "# times, if you have multiple columns with data errors."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3335ff62",
      "metadata": {
        "id": "3335ff62"
      },
      "source": [
        "### So we have failed the exercise, and we can see from the AssertionError that our returned output does not match the expected (solution) output.\n",
        "\n",
        "### What do we do now?\n",
        "\n",
        "Again, the **AssertionError** message from the function is not quite as direct as before, but we can see that some values in the column `count` are different."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e85b253d",
      "metadata": {
        "id": "e85b253d"
      },
      "source": [
        "### But wait, we changed the values in two of the columns, and the error message is only giving one column as having incorrect values? Is the test wrong?\n",
        "\n",
        "#### No, the test is functioning correctly. The `assert_frame_equal()` function will return the first column that has a difference in values, with the error on that column. If this is the error, you may end up fixing the error in the first column and then finding out that an additional column(s) may also be incorrect."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f753451",
      "metadata": {
        "id": "9f753451"
      },
      "source": [
        "### What we recommend is running the pandas  function `compare()`, to give all of the rows with different values. This is a very good function.\n",
        "\n",
        "Let's look at the documentation:  https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.compare.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f626bd4f",
      "metadata": {
        "id": "f626bd4f"
      },
      "outputs": [],
      "source": [
        "# # note that the \"self\" df is the df that we are running compare on\n",
        "# # and the \"other\" df is the one in the parenthesis (we are comparing to)\n",
        "display(true_output_vars['output_0'].compare(returned_output_vars['output_0']))\n",
        "\n",
        "# # align the differences on rows, just a different way of looking at the comparison\n",
        "display(true_output_vars['output_0'].compare(returned_output_vars['output_0'],align_axis=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4f8dd10",
      "metadata": {
        "id": "d4f8dd10"
      },
      "source": [
        "### Now that you know the differences, you are going to have to go back to your code and find/correct what you have written wrong.\n",
        "\n",
        "1. Go back to the line(s) of code that produced the difference(s).\n",
        "\n",
        "2. Go back into your code directly and walk through each step, comparing it the requirement/step that it executes, to see if you can find the error.\n",
        "\n",
        "    ***Some examples include:***\n",
        "\n",
        "\n",
        "    1. You have written a math code equation wrong.\n",
        "\n",
        "    2. You are incorrectly assigning a value.\n",
        "\n",
        "    3. You have some string manipulation wrong.\n",
        "\n",
        "    4. You have a logic error.\n",
        "\n",
        "    5. You have sorted incorrectly (or failed to sort when you should have).\n",
        "\n",
        "    6. You have incorrectly rounded numeric data (or failed to round when you should have)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63013ec8",
      "metadata": {
        "id": "63013ec8"
      },
      "source": [
        "## One final note, concerning the demo cells."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aca2321f",
      "metadata": {
        "id": "aca2321f"
      },
      "source": [
        "### The demo cells are designed to give you some sample data, to help you to get your code up and running. You will see these for every exercise on all of the exams.\n",
        "\n",
        "## Note that I can pass the demo cell and still fail the test cell!!!\n",
        "\n",
        "This will be ***ONE OF THE BIGGEST PROBLEMS*** for students on the exams.\n",
        "\n",
        "Students think that, because they passed the DEMO CELL, it means that they WILL ALSO pass the TEST CELL.\n",
        "\n",
        "This IS NOT the case, as the DEMO CELL is designed to give you some SAMPLE DATA, to help you get your code up and running."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "142a2bf2",
      "metadata": {
        "id": "142a2bf2"
      },
      "source": [
        "## The DEMO CELL IS NOT a full test of your code, and you can easily pass the DEMO CELL and FAIL the TEST CELL!!!\n",
        "\n",
        "## The TEST CELL is a FULL TEST of your code, and it is much more extensive than the DEMO CELL.\n",
        "\n",
        "## So be aware that you can pass the DEMO CELL and still fail the TEST CELL."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0079dd73",
      "metadata": {
        "id": "0079dd73"
      },
      "source": [
        "***\n",
        "***ON EVERY EXAM***, there will be ***AT LEAST 20 Piazza posts*** from students whose code passes the demo cell and fails the test cell. They will post that there is a BUG in the exam because of this, when in fact, their code is incorrect.\n",
        "\n",
        "Please be aware of this difference between the demo and test cells.\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "656628da",
      "metadata": {
        "id": "656628da"
      },
      "source": [
        "## What are your questions concerning data troubleshooting of pandas dataframes?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}